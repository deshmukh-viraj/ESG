{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d829f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import dagshub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a216fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"data_path\": \"C:\\\\ESG\\\\data\\\\processed_esg_dataset.csv\",\n",
    "    \"test_size\": 0.25,\n",
    "    \"mlflow_tracing_uri\": \"https://dagshub.com/virajdeshmukh080818/ESG.mlflow\",\n",
    "    \"dagshub_repo_owner\": \"virajdeshmukh080818\",\n",
    "    \"dagshub_repo_name\": \"ESG\",\n",
    "    \"experiment_name\": \"Traing Advanced Models\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5236fdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as virajdeshmukh080818\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as virajdeshmukh080818\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"virajdeshmukh080818/ESG\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"virajdeshmukh080818/ESG\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository virajdeshmukh080818/ESG initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository virajdeshmukh080818/ESG initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/47fefc0ac8fe470a9a3037536f9dffe9', creation_time=1754685677086, experiment_id='1', last_update_time=1754685677086, lifecycle_stage='active', name='Traing Advanced Models', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(CONFIG['mlflow_tracing_uri'])\n",
    "dagshub.init(repo_owner=CONFIG['dagshub_repo_owner'], repo_name=CONFIG['dagshub_repo_name'], mlflow=True)\n",
    "mlflow.set_experiment(CONFIG['experiment_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80225d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\ESG\\data\\\\processed_esg_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72c6189",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('MarketCap', axis=1)\n",
    "y = data['MarketCap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380559db",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, n_jobs=-1, verbosity=0),\n",
    "    \"LightGBM\": LGBMRegressor(random_state=42, n_jobs=-1),\n",
    "    \"CatBoost\": CatBoostRegressor(random_state=42, silent=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f436fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring_r2 = make_scorer(r2_score)\n",
    "scoring_mae = make_scorer(mean_absolute_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7e0e6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3086\n",
      "[LightGBM] [Info] Number of data points in the train set: 8800, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 13178.413854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3085\n",
      "[LightGBM] [Info] Number of data points in the train set: 8800, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 13463.558632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3085\n",
      "[LightGBM] [Info] Number of data points in the train set: 8800, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 13714.745343\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3086\n",
      "[LightGBM] [Info] Number of data points in the train set: 8800, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 13156.333794\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3086\n",
      "[LightGBM] [Info] Number of data points in the train set: 8800, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 13390.059564\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3086\n",
      "[LightGBM] [Info] Number of data points in the train set: 8800, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 13178.413854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3085\n",
      "[LightGBM] [Info] Number of data points in the train set: 8800, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 13463.558632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3085\n",
      "[LightGBM] [Info] Number of data points in the train set: 8800, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 13714.745343\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3086\n",
      "[LightGBM] [Info] Number of data points in the train set: 8800, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 13156.333794\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3086\n",
      "[LightGBM] [Info] Number of data points in the train set: 8800, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 13390.059564\n",
      "Models Performance Comaparison: \n",
      "          Model   Mean R2    Std R2     Mean MAE     Std MAE\n",
      "3      CatBoost  0.901589  0.034403  3293.123017  290.831145\n",
      "0  RandomForest  0.888711  0.034887  3359.519506  274.931223\n",
      "1       XGBoost  0.870270  0.028121  3589.912276  247.679061\n",
      "2      LightGBM  0.864237  0.041331  3597.757332  339.253844\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for name, model in models.items():\n",
    "    r2_scores = cross_val_score(model, X,y, cv=kf, scoring=scoring_r2)\n",
    "    mae_scores = cross_val_score(model, X,y, cv=kf, scoring=scoring_mae)\n",
    "\n",
    "    result.append({\n",
    "        \"Model\": name,\n",
    "        \"Mean R2\": np.mean(r2_scores),\n",
    "        \"Std R2\": np.std(r2_scores),\n",
    "        \"Mean MAE\": -np.mean(mae_scores),\n",
    "        \"Std MAE\": np.std(mae_scores)\n",
    "    })\n",
    "\n",
    "result_df = pd.DataFrame(result).sort_values(by=\"Mean R2\", ascending=False)\n",
    "print(\"Models Performance Comaparison: \")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba12529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CatBoost as CatBoost_best_model.pkl\n",
      "Saved RandomForest as RandomForest_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "top_models = result_df.head(2)['Model'].values\n",
    "for name in top_models:\n",
    "    model = models[name]\n",
    "    model.fit(X,y)\n",
    "    joblib.dump(model, f'{name}_best_model.pkl')\n",
    "    print(f'Saved {name} as {name}_best_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
